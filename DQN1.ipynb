{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7c9685-59a9-4230-9bbf-a8d2f8d1988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from collections import deque\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65f41b2-df07-4805-b973-a46fc4c24293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "STATE_SIZE = 8  # Select relevant features\n",
    "ACTION_SIZE = 2  # Genuine (0) or Misbehaving (1)\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.001\n",
    "MEMORY_SIZE = 2000\n",
    "BATCH_SIZE = 32\n",
    "TARGET_UPDATE_FREQUENCY = 5  # Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad11f6e-ad4f-48e7-a91b-ec736c451a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    features = ['spdx', 'spdy', 'aclx', 'acly', 'hedx', 'hedy', 'posx', 'posy']\n",
    "    target = 'class'\n",
    "    X = df[features].values\n",
    "    y = df[target].values\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0910c222-83b4-420c-9ff6-62c8235738ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Model\n",
    "def create_model(state_size, action_size):\n",
    "    model = Sequential([\n",
    "        Input(shape=(state_size,)), \n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(action_size, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81edb990-0308-4608-be82-193d8eae6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "        self.model = create_model(state_size, action_size)\n",
    "        self.target_model = create_model(state_size, action_size)\n",
    "        self.update_target_model()\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.1\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_size)\n",
    "        q_values = self.model.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "\n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        for state, action, reward, next_state, done in batch:\n",
    "            target = self.model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                t = self.target_model.predict(next_state)\n",
    "                target[0][action] = reward + GAMMA * np.amax(t[0])\n",
    "\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d05e5df-2bb6-4faf-b2ed-728c772a8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate\n",
    "def train_dqn(X, y, episodes=10):\n",
    "    agent = DQNAgent(STATE_SIZE, ACTION_SIZE)\n",
    "    for e in range(episodes):\n",
    "        indices = np.random.choice(len(X), 20, replace=False)\n",
    "    state = np.reshape(X[indices[0]], [1, STATE_SIZE])\n",
    "    for t in range(len(indices)):\n",
    "        action = agent.act(state)\n",
    "        reward = 1 if action == y[indices[t]] else -1\n",
    "        next_state = np.reshape(X[indices[t]], [1, STATE_SIZE]) if t < len(indices) - 1 else None\n",
    "        done = t == len(indices) - 1\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(f\"Episode {e+1}/{episodes}, Epsilon: {agent.epsilon:.2f}\")\n",
    "            break\n",
    "\n",
    "\n",
    "        # Replay and update target network\n",
    "        agent.replay()\n",
    "        if e % TARGET_UPDATE_FREQUENCY == 0:\n",
    "            agent.update_target_model()\n",
    "\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cc54e6e-30c8-4eb6-b338-8d8b6b521d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "\n",
    "def evaluate(agent, X_test, y_test):\n",
    "    y_pred = []\n",
    "    for state in X_test:\n",
    "        state = np.reshape(state, [1, state.shape[0]])\n",
    "        action = agent.act(state)\n",
    "        y_pred.append(action)\n",
    "    \n",
    "    recall = recall_score(y_test, y_pred, average='macro')  # Use macro for multiclass\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Recall: {recall:.2f}, F1 Score: {f1:.2f}, Accuracy: {accuracy:.2f}\")\n",
    "    return recall, f1, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ad81568-0f03-4ed8-be3a-ad25ec66f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10/10, Epsilon: 1.00\n",
      "Recall: 0.05, F1 Score: 0.03, Accuracy: 0.30\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"C:/Users/Elroofey/Desktop/mixalldata_clean.csv\"  # Replace with your dataset path\n",
    "    X, y = load_data(filepath)\n",
    "    split = int(0.8 * len(X))\n",
    "    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "    agent = train_dqn(X_train, y_train)\n",
    "    evaluate(agent, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12267fe-75dd-4776-b00f-49ad4de64ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
